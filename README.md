
# **Sketch-to-Photo, Image-to-Image Translation with GAN**

Michael Bocelli

_Abstract - This paper serves to investigate the capabilities of generative adversarial networks (GANs) in regards to image-to-image translation. Many prior works have experimented with image translation as a task for GANs, and this paper intends to add to the growing field by specifically investigating the problem of translating an image from an abstract domain to one of higher fidelity. Through testing different GAN architectures, we hope to find what makes a given model a good fit for this particular type of translation. Specifically, the paper will compare the results of a model that relies on paired training data, and one that uses unpaired generation. It will be demonstrated that paired training dominates when translating an image from an abstract domain, however, this does not mean that the unpaired model is not without its use cases. For instance, the reader will see that the unpaired model produces two generators for bidirectional translation, and perhaps could be trained further to better match the results of the paired model._
